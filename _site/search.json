[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "posts/Regression Analysis - Predicting Homeownership in R/index.html",
    "href": "posts/Regression Analysis - Predicting Homeownership in R/index.html",
    "title": "Regression Analysis - Predicting Homeownership in R",
    "section": "",
    "text": "This Project seeks to understand the dynamics of home ownership within the labor force of the United States using data sourced from the American Community Survey (ACS).\nHome ownership Reflects the Social and economic aspects of an individual’s life, and the ability to own a home is an important economic indicator. this project looks to find the most important factors determining if one can own a home, and creates an interesting visualization which can aid anyone looking to own a home find the right U.S State for them.\n\n\nThis data from the ACS shows home ownership by state. Note that (1) is Owned/Loaned, (2) is Renter, and (3) is Neither. Note that states are represented by their FIPS codes. Later, we’ll change this to state abbreviations when we make state-specific predictions.\n\n\n\n\nThis Project makes use of Linear Regression and a step-wise function, all done in R. From this, we can see our Coefficients. Remember, a high coefficient indicates that the corresponding predictor variable has a strong influence on the outcome, which in this case is home ownership. Some of our most important predictors are Income, Poverty, Marriage status, and education.\n\n\n\n\nNow, for a visualization that can help inform your next move, here is a visualization of the predicted probability of owning a home dependent on your state.\n\nThe descriptive analysis, Regression and predicted probabilities in this project use analytics tools to inform about homeownership, an important economic and social aspect of everyone’s life. to learn more about the project, feel free to check out my github page."
  },
  {
    "objectID": "posts/Regression Analysis - Predicting Homeownership in R/index.html#introduction",
    "href": "posts/Regression Analysis - Predicting Homeownership in R/index.html#introduction",
    "title": "Regression Analysis - Predicting Homeownership in R",
    "section": "",
    "text": "This Project seeks to understand the dynamics of home ownership within the labor force of the United States using data sourced from the American Community Survey (ACS).\nHome ownership Reflects the Social and economic aspects of an individual’s life, and the ability to own a home is an important economic indicator. this project looks to find the most important factors determining if one can own a home, and creates an interesting visualization which can aid anyone looking to own a home find the right U.S State for them.\n\n\nThis data from the ACS shows home ownership by state. Note that (1) is Owned/Loaned, (2) is Renter, and (3) is Neither. Note that states are represented by their FIPS codes. Later, we’ll change this to state abbreviations when we make state-specific predictions.\n\n\n\n\nThis Project makes use of Linear Regression and a step-wise function, all done in R. From this, we can see our Coefficients. Remember, a high coefficient indicates that the corresponding predictor variable has a strong influence on the outcome, which in this case is home ownership. Some of our most important predictors are Income, Poverty, Marriage status, and education.\n\n\n\n\nNow, for a visualization that can help inform your next move, here is a visualization of the predicted probability of owning a home dependent on your state.\n\nThe descriptive analysis, Regression and predicted probabilities in this project use analytics tools to inform about homeownership, an important economic and social aspect of everyone’s life. to learn more about the project, feel free to check out my github page."
  },
  {
    "objectID": "posts/Creating a SQL Database for a property management company/index.html",
    "href": "posts/Creating a SQL Database for a property management company/index.html",
    "title": "Creating and Maintaining a Database for a Property Management COmpany",
    "section": "",
    "text": "With this project, we make use of ER diagrams to guide us in creating a database using SQL on ms SQL server. We also query data from the database to simulate business situations. Our database is for an apartment complex, where we make sure to account for the number of apartments, tenants, maintenance, rooms, and more. This database can be used by a company to facilitate all information regarding their apartments, from leases to specifications.\n\n\nHere, you can see the relational model which aided in guiding the modeling of the database.\n\nBe sure to check out the statements used to create the database on my github repository. It also includes statements to be used in different scenarios, querying specific information to aid business processes."
  },
  {
    "objectID": "posts/Creating a SQL Database for a property management company/index.html#introduction",
    "href": "posts/Creating a SQL Database for a property management company/index.html#introduction",
    "title": "Creating and Maintaining a Database for a Property Management COmpany",
    "section": "",
    "text": "With this project, we make use of ER diagrams to guide us in creating a database using SQL on ms SQL server. We also query data from the database to simulate business situations. Our database is for an apartment complex, where we make sure to account for the number of apartments, tenants, maintenance, rooms, and more. This database can be used by a company to facilitate all information regarding their apartments, from leases to specifications.\n\n\nHere, you can see the relational model which aided in guiding the modeling of the database.\n\nBe sure to check out the statements used to create the database on my github repository. It also includes statements to be used in different scenarios, querying specific information to aid business processes."
  },
  {
    "objectID": "posts/AISentimentAnalysis/index.html",
    "href": "posts/AISentimentAnalysis/index.html",
    "title": "Sentiment Through Time - A Multi-Year Analysis of Scholarly and Public Discourse on AI",
    "section": "",
    "text": "The Primary goal of this project is to understand any trends in the sentiment of scholarly and popular literature regarding AI across recent history. This is achieved through gathering and processing data, creating a timeline of major events regarding AI, and analyzing text data in R to spot trends over time.\n\n\nData was collected from multiple sources, with a system in place to ensure relevant data that would yield significant and accurate results.\nSo how was data acquired?\n\nResearch and opinion articles pulled through Google Scholar.\n\nKeyword Search: AI.\nSorted for Most Relevant in each given year.\nonly articles containing opinionated wording selected. No neutral-toned research/academic articles.\nArticles that could not be accessed were skipped.\n60 Articles chosen in total.\n\n\n\n\n\nBelow is a bar graph visualizing the percentage of positive net sentiment each year.\n\n\n\n\nThe dip in sentiment in 2022 coincides with the release of ChatGPT. This May be due to early skepticism of the technology. The growing positive sentiment after the fact may be due to the subsequent integration of AI in daily life, and the acknowledgement of AI’s benefits by formerly skeptical parties.\n\n\n\n(2021,2022, and 2023 word clouds respectively)"
  },
  {
    "objectID": "posts/AISentimentAnalysis/index.html#introduction",
    "href": "posts/AISentimentAnalysis/index.html#introduction",
    "title": "Sentiment Through Time - A Multi-Year Analysis of Scholarly and Public Discourse on AI",
    "section": "",
    "text": "The Primary goal of this project is to understand any trends in the sentiment of scholarly and popular literature regarding AI across recent history. This is achieved through gathering and processing data, creating a timeline of major events regarding AI, and analyzing text data in R to spot trends over time.\n\n\nData was collected from multiple sources, with a system in place to ensure relevant data that would yield significant and accurate results.\nSo how was data acquired?\n\nResearch and opinion articles pulled through Google Scholar.\n\nKeyword Search: AI.\nSorted for Most Relevant in each given year.\nonly articles containing opinionated wording selected. No neutral-toned research/academic articles.\nArticles that could not be accessed were skipped.\n60 Articles chosen in total.\n\n\n\n\n\nBelow is a bar graph visualizing the percentage of positive net sentiment each year.\n\n\n\n\nThe dip in sentiment in 2022 coincides with the release of ChatGPT. This May be due to early skepticism of the technology. The growing positive sentiment after the fact may be due to the subsequent integration of AI in daily life, and the acknowledgement of AI’s benefits by formerly skeptical parties.\n\n\n\n(2021,2022, and 2023 word clouds respectively)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My journey into the world of analytics began with a curiosity to understand the hidden stories within statistics. Throughout my academic, personal and professional career, I have developed a thorough skill set enabling me to perform data analysis, statistical modeling, machine learning, data visualization, and much more.\nIn partnership with these tools are a constant drive for growth, a refined ability in communication, and a passion for collaborative problem solving. These qualities are the bread and butter in my approach to data science, enabling me to not just analyze data but effectively convey its meaning and insights to drive significant change.\nTECHNICAL SKILLS\n\nR Programming - data manipulation, visualization, and analysis.\nSQL - database creation and maintenance.\nSAS - advanced analytics and business intelligence.\nSAS Data Miner - discover patterns within data for predictive modeling.\nSPSS - statistical data analysis.\nTableau - Data visualization and dashboards.\nPowerBI - Data Visualization and process automation.\nMicrosoft Office Suite - productivity tools including Word, Excel, PowerPoint etc.\nExcel - spreadsheet software for analysis.\n\nEDUCATION\nRichards College of Business, University of West Georgia -\nBachelor of Business Administration: Data Intelligence and Business Analytics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Noel Mangai",
    "section": "",
    "text": "Hello! I’m Noel, A dedicated enthusiast with a background in Data Intelligence and Business Analytics, and a proud graduate from the University of West Georgia. I invite you to look into my projects, where i showcase my blend of creative problem solving with technical expertise. Join me as I share the hidden stories within numbers."
  },
  {
    "objectID": "posts/Arima Forecasting/index.html",
    "href": "posts/Arima Forecasting/index.html",
    "title": "Predicting the GDP of China in R",
    "section": "",
    "text": "This project aims to perform forecasting in R using ARIMA modeling, autocorrelation functions, and ETS models. The Image below displays the final ARIMA forecast.\n\n\n\nTo get this analysis started, the CNAGDP.csv file from the Federal Reserve of Economic Data (FRED) is read in. Some pre-processing steps involve turning it into a time series tibble and visualizing the data.\n\n\n\nFollowing this, I calculate the Autocorrelation Function (ACF) of the variable MKTGDPCNA646NWDB to analyze its correlation with its lagged values\n\n\n\n\nAn exponential smoothing model is fitted using the ‘ets’ function, and that is followed up by creating a one step forecast using the ‘forecast’ function.\n\n\n\nFinally, it is time for the Auto Regressive Integrated Moving Average (ARIMA) Model, created using the ‘auto.arima’ function.\nthis function is great because it automatically selects the best ARIMA model based on my data. a one-step-ahead forecast is created, and the plot of our forecast, which you have seen above, is created."
  },
  {
    "objectID": "posts/Arima Forecasting/index.html#introduction",
    "href": "posts/Arima Forecasting/index.html#introduction",
    "title": "Predicting the GDP of China in R",
    "section": "",
    "text": "This project aims to perform forecasting in R using ARIMA modeling, autocorrelation functions, and ETS models. The Image below displays the final ARIMA forecast.\n\n\n\nTo get this analysis started, the CNAGDP.csv file from the Federal Reserve of Economic Data (FRED) is read in. Some pre-processing steps involve turning it into a time series tibble and visualizing the data.\n\n\n\nFollowing this, I calculate the Autocorrelation Function (ACF) of the variable MKTGDPCNA646NWDB to analyze its correlation with its lagged values\n\n\n\n\nAn exponential smoothing model is fitted using the ‘ets’ function, and that is followed up by creating a one step forecast using the ‘forecast’ function.\n\n\n\nFinally, it is time for the Auto Regressive Integrated Moving Average (ARIMA) Model, created using the ‘auto.arima’ function.\nthis function is great because it automatically selects the best ARIMA model based on my data. a one-step-ahead forecast is created, and the plot of our forecast, which you have seen above, is created."
  },
  {
    "objectID": "posts/Microsoft Research Project - Consumer Sentiment/index.html",
    "href": "posts/Microsoft Research Project - Consumer Sentiment/index.html",
    "title": "Microsoft Research Project - Consumer Sentiments",
    "section": "",
    "text": "Microsoft was founded in 1975 and grew into a technological powerhouse, reaching a market cap of $35 billion by 1995. Almost 3 decades later, this company is now valued at $3 trillion, making it the largest company in the world, followed by its long-time competitor, Apple, at $2.26 trillion. \nMicrosoft’s strategy has been one focused on providing software to both consumers and organizations, as well as hardware to meet customer’s needs as they arise. In their Fiscal Year 2023 earnings call, Microsoft’s CEO, Satya Nadella, explained their focus on three key priorities: \n“First, helping customers use the breadth and depth of Microsoft Cloud to get the most value out of their spend. Second, investing to lead in the new AI platform shift by infusing AI across every layer of the tech stack. And, third, driving operating leverage.” \nWith these key priorities in mind, we analyze this data in order to aid the company in realizing its goals, gathering customer sentiment data in various hardware and software.\n\n\nThe questionnaire used for our data was created on Qualtrics. Using an anonymous link, it was disseminated to students, faculty, staff, family, and friends.\nThe questionnaire consists of twenty-five questions. Sixteen of these are Likert-scale allowing respondents to rate their experiences ranging from strongly agree to strongly disagree. Another three were nominal-scaled, inquiring names, labels, and identifications. Six of the questions that were used for the questionnaire were ratio-scaled, created to answer open-ended questions.\nAll responses were collected through online platforms. We did not focus our data collection on any specific part of the campus. Respondents that participated in the questionnaire totaled at 385, so as to achieve a significant amount of responses for statistical operations. All data was transferred into SPSS and used for statistical analysis.\n\n\n\n\n\n\n\n\nThis analysis gave us insight into what customers really think about Microsoft as a whole, regarding their products, effectiveness, and customer satisfaction. Our survey yielded approximately 385 respondents, and each question answered was used to create statistical data. We examined all of these statistical analysis and came to the following conclusions:\nOur test of one proportion of gender revealed that our sample is representative of UWG’s undergraduate population of females. Both males and females had similar means for the following variables:\n\nI would recommend Microsoft to a peer/friend \nI am satisfied with Microsoft’s prices\nI would use Microsoft more if its prices were different \nMicrosoft fits my specific needs well \nMicrosoft has a wide array of products that I would use \n\nThe strong majority of respondents agreed to some degree that Microsoft’s products are effective in the workplace. When questioned on  the advertising effectiveness of Microsoft’s products, roughly 59 percent of respondents agreed to some degree, leaving a considerable margin for improvement.\nThe full report, Including all statistical processes such as chi square tests, tests of differences between means, ARIMA, test of one mean and more are available on my github repository."
  },
  {
    "objectID": "posts/Microsoft Research Project - Consumer Sentiment/index.html#introduction",
    "href": "posts/Microsoft Research Project - Consumer Sentiment/index.html#introduction",
    "title": "Microsoft Research Project - Consumer Sentiments",
    "section": "",
    "text": "Microsoft was founded in 1975 and grew into a technological powerhouse, reaching a market cap of $35 billion by 1995. Almost 3 decades later, this company is now valued at $3 trillion, making it the largest company in the world, followed by its long-time competitor, Apple, at $2.26 trillion. \nMicrosoft’s strategy has been one focused on providing software to both consumers and organizations, as well as hardware to meet customer’s needs as they arise. In their Fiscal Year 2023 earnings call, Microsoft’s CEO, Satya Nadella, explained their focus on three key priorities: \n“First, helping customers use the breadth and depth of Microsoft Cloud to get the most value out of their spend. Second, investing to lead in the new AI platform shift by infusing AI across every layer of the tech stack. And, third, driving operating leverage.” \nWith these key priorities in mind, we analyze this data in order to aid the company in realizing its goals, gathering customer sentiment data in various hardware and software.\n\n\nThe questionnaire used for our data was created on Qualtrics. Using an anonymous link, it was disseminated to students, faculty, staff, family, and friends.\nThe questionnaire consists of twenty-five questions. Sixteen of these are Likert-scale allowing respondents to rate their experiences ranging from strongly agree to strongly disagree. Another three were nominal-scaled, inquiring names, labels, and identifications. Six of the questions that were used for the questionnaire were ratio-scaled, created to answer open-ended questions.\nAll responses were collected through online platforms. We did not focus our data collection on any specific part of the campus. Respondents that participated in the questionnaire totaled at 385, so as to achieve a significant amount of responses for statistical operations. All data was transferred into SPSS and used for statistical analysis.\n\n\n\n\n\n\n\n\nThis analysis gave us insight into what customers really think about Microsoft as a whole, regarding their products, effectiveness, and customer satisfaction. Our survey yielded approximately 385 respondents, and each question answered was used to create statistical data. We examined all of these statistical analysis and came to the following conclusions:\nOur test of one proportion of gender revealed that our sample is representative of UWG’s undergraduate population of females. Both males and females had similar means for the following variables:\n\nI would recommend Microsoft to a peer/friend \nI am satisfied with Microsoft’s prices\nI would use Microsoft more if its prices were different \nMicrosoft fits my specific needs well \nMicrosoft has a wide array of products that I would use \n\nThe strong majority of respondents agreed to some degree that Microsoft’s products are effective in the workplace. When questioned on  the advertising effectiveness of Microsoft’s products, roughly 59 percent of respondents agreed to some degree, leaving a considerable margin for improvement.\nThe full report, Including all statistical processes such as chi square tests, tests of differences between means, ARIMA, test of one mean and more are available on my github repository."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Sentiment Through Time - A Multi-Year Analysis of Scholarly and Public Discourse on AI\n\n\n\nR\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nNoel Mangai\n\n\nApr 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMicrosoft Research Project - Consumer Sentiments\n\n\n\nSPSS\n\n\nExcel\n\n\nResearch\n\n\nanalysis\n\n\nQualtrics\n\n\n\n\n\n\n\n\n\n\nApr 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression Analysis - Predicting Homeownership in R\n\n\n\nR\n\n\ncode\n\n\nanalysis\n\n\nmachine learning\n\n\n\n\n\n\n\nNoel Mangai\n\n\nApr 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating and Maintaining a Database for a Property Management COmpany\n\n\n\nSQL\n\n\ncode\n\n\ndatabase\n\n\n\n\n\n\n\nNoel Mangai\n\n\nApr 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting the GDP of China in R\n\n\n\nR\n\n\ncode\n\n\nanalysis\n\n\nForecasting\n\n\n\n\n\n\n\nNoel Mangai\n\n\nNov 21, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]